{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "889f6a2a-64f5-48be-adea-4317784652da",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# pyspark functions\n",
    "from pyspark.sql.functions import *\n",
    "# URL processing\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d2946a9-9366-496e-ba32-b91098838b40",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the path to the Delta table\n",
    "delta_table_path = \"dbfs:/user/hive/warehouse/authentication_credentials\"\n",
    "\n",
    "# Read the Delta table to a Spark DataFrame\n",
    "aws_keys_df = spark.read.format(\"delta\").load(delta_table_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0e23754-2764-4cc6-8888-2da3902e9b60",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get the AWS access key and secret key from the spark dataframe\n",
    "ACCESS_KEY = aws_keys_df.select('Access key ID').collect()[0]['Access key ID']\n",
    "SECRET_KEY = aws_keys_df.select('Secret access key').collect()[0]['Secret access key']\n",
    "# Encode the secrete key\n",
    "ENCODED_SECRET_KEY = urllib.parse.quote(string=SECRET_KEY, safe=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "657fe7aa-22a5-44cc-abbb-cc1a0d4c99af",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# AWS S3 bucket name s3://user-12e98c45f0cb-bucket/topics/12e98c45f0cb.pin/partition=0/\n",
    "AWS_S3_BUCKET = \"\"\n",
    "# Mount name for the bucket\n",
    "MOUNT_NAME = \"/mnt/pinterest_mount\"\n",
    "# Source url \n",
    "SOURCE_URL = \"s3n://{0}:{1}@{2}\".format(ACCESS_KEY, ENCODED_SECRET_KEY, AWS_S3_BUCKET)\n",
    "# Mount the drive\n",
    "dbutils.fs.mount(SOURCE_URL, MOUNT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "737f2e55-091b-4968-a964-7666c9a7135d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(MOUNT_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a962a7a-c2c6-494e-87b1-05f7f8244d60",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "--  Disable format checks during the reading of Delta tables\n",
    "SET spark.databricks.delta.formatCheck.enabled=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4770844e-e63b-4eed-8fe0-87e0e12de976",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# File location and type\n",
    "# Asterisk(*) indicates reading all the content of the specified file that have .json extension\n",
    "file_location = \"/mnt/pinterest_mount/topics/<TOPIC NAME>/partition=0/*.json\"\n",
    "file_type = \"json\"\n",
    "# Ask Spark to infer the schema\n",
    "infer_schema = \"true\"\n",
    "# Read in JSONs from mounted S3 bucket\n",
    "df_user = spark.read.format(file_type) \\\n",
    ".option(\"inferSchema\", infer_schema) \\\n",
    ".load(file_location)\n",
    "display(df_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bcdb10ae-fda1-4775-8773-e3e8c053a43e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Assuming your DataFrame is named df\n",
    "df_user.write \\\n",
    "  .format(\"parquet\") \\\n",
    "  .mode(\"overwrite\") \\\n",
    "  .option(\"path\", \"\") \\\n",
    "  .saveAsTable(\"12e98c45f0cb_user\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d952d402-e17a-46f2-8a78-2aa8b6ed6f1b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cleaned_pin1 = df_pin.replace({'User Info Error': None,\n",
    "                               'No description available Story format':None,\n",
    "                               'Image src error.':None,\n",
    "                               'N,o, ,T,a,g,s, ,A,v,a,i,l,a,b,l,e':None,\n",
    "                               'No Title Data Available':None\n",
    "                               })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2bf44be7-f89d-47a8-b8c9-0bdd9bc50f3f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cleaned_pin2 = cleaned_pin1.withColumn('follower_count', \n",
    "                                       when(col('follower_count').endswith('k'), regexp_replace(col('follower_count'), 'k', '').cast('int') * 1000)\n",
    "                                       .when(col('follower_count').endswith('M'), regexp_replace(col('follower_count'), 'M', '').cast('int') * 1000000)\n",
    "                                       .otherwise(col('follower_count').cast('int')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12ee1a0b-cce3-4d42-a7ec-9497f78687da",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cleaned_pin3 = (cleaned_pin2\n",
    "                #.withColumn(\"follower_count\", cleaned_pin2[\"follower_count\"].cast('float'))\n",
    "                .withColumn(\"downloaded\", cleaned_pin2[\"downloaded\"].cast('int'))\n",
    "                .withColumn(\"ind\", cleaned_pin2[\"index\"].cast('int')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b624da9-5824-4c7b-a8d9-78e2869cf6c6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cleaned_pin4 = cleaned_pin3.withColumn('save_location', regexp_replace('save_location','Local save in ', \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67bec647-a8f4-4ae1-a4bf-fa9eeef344ec",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cleaned_pin5 = cleaned_pin4.select('ind', 'unique_id', 'title', 'description', 'follower_count', 'poster_name', 'tag_list', 'is_image_or_video', 'image_src', 'save_location', 'category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43ca62d4-0761-485b-94fe-4aee2488c0c4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cleaned_pin5.write.mode(\"overwrite\").saveAsTable(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91d27434-e0e2-48dd-b876-954b3a200e2d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "clean_geo = df_geo.withColumn(\"coordinates\", array(\"latitude\", \"longitude\"))\n",
    "clean_geo = clean_geo.drop(\"latitude\", \"longitude\")\n",
    "clean_geo = clean_geo.withColumn(\"timestamp\", to_timestamp(\"timestamp\"))\n",
    "clean_geo = clean_geo.select(\"ind\", \"country\", \"coordinates\", \"timestamp\")\n",
    "\n",
    "display(clean_geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7563adf7-894f-40ce-bfe9-ae9648c506fc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "clean_geo.write.mode(\"overwrite\").saveAsTable(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99f2c0a8-b9df-4478-84ea-47a7df12f65b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "clean_user = df_user.withColumn(\"user_name\", concat_ws(\" \", \"first_name\", \"last_name\"))\n",
    "clean_user = clean_user.drop(\"first_name\", \"last_name\")\n",
    "clean_user = clean_user.withColumn(\"date_joined\", to_timestamp(\"date_joined\"))\n",
    "clean_user = clean_user.select(\"ind\", \"user_name\", \"age\", \"date_joined\")\n",
    "\n",
    "display(clean_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7d6345e-3c0b-40a7-aac7-2371d51722e3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "clean_user.write.mode(\"overwrite\").saveAsTable(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe26fee3-b8f3-47e2-b9d6-b08bd3a22586",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Find the most popular catehory in each country\n",
    "\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import rank\n",
    "\n",
    "df_pin_geo = cleaned_pin5.join(clean_geo, cleaned_pin5.ind == clean_geo.ind, \"inner\")\n",
    "\n",
    "popular_category_by_country = df_pin_geo.groupBy(\"country\", \"category\") \\\n",
    "                                        .agg(count(\"category\").alias(\"category_count\")) \\\n",
    "                                        .orderBy(\"country\", col(\"category_count\").desc())\n",
    "\n",
    "windowSpec = Window.partitionBy(\"country\").orderBy(col(\"category_count\").desc())\n",
    "\n",
    "popular_category_by_country = popular_category_by_country.withColumn(\"rank\", rank().over(windowSpec)) \\\n",
    "                                                         .filter(col(\"rank\") == 1) \\\n",
    "                                                         .drop(\"rank\")\n",
    "\n",
    "display(popular_category_by_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bbecd9a2-3701-4fc0-99f1-38c6af7faa73",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Find the user with the most followers in each country\n",
    "\n",
    "df_geo_user = clean_user.join(clean_geo, clean_user.ind == clean_geo.ind, \"inner\")\n",
    "df_all = df_geo_user.join(cleaned_pin5, clean_user.ind == cleaned_pin5.ind, \"inner\")\n",
    "\n",
    "most_followed_user_by_country = df_all.select(\"country\", \"user_name\", \"follower_count\").dropDuplicates()\n",
    "\n",
    "most_followed_user_by_country = most_followed_user_by_country.orderBy(col(\"follower_count\").desc()).limit(1)\n",
    "display(most_followed_user_by_country)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6597154c-f25a-4a21-bc7f-c16519c91bc6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# What is the most popular category per age group?\n",
    "\n",
    "df_geo_user = clean_user.join(clean_geo, clean_user.ind == clean_geo.ind, \"inner\")\n",
    "df_all = df_geo_user.join(cleaned_pin5, clean_user.ind == cleaned_pin5.ind, \"inner\")\n",
    "\n",
    "df_age_group = df_all.withColumn(\"age_group\", when((col(\"age\") >= 18) & (col(\"age\") <= 24), \"18-24\")\n",
    "                              .when((col(\"age\") >= 25) & (col(\"age\") <= 35), \"25-35\")\n",
    "                              .when((col(\"age\") >= 36) & (col(\"age\") <= 50), \"36-50\")\n",
    "                              .when(col(\"age\") > 50, \"+50\"))\n",
    "\n",
    "result_df = df_age_group.groupBy(\"age_group\", \"category\").agg(count(\"category\").alias(\"category_count\"))\n",
    "\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "\n",
    "windowSpec = Window.partitionBy(\"age_group\").orderBy(col(\"category_count\").desc())\n",
    "\n",
    "result_df = result_df.withColumn(\"rank\", rank().over(windowSpec)) \\\n",
    "                     .filter(col(\"rank\") == 1) \\\n",
    "                     .drop(\"rank\")\n",
    "\n",
    "result_df = result_df.select('age_group', 'category', 'category_count')\n",
    "\n",
    "display(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c20b295-ad9b-4cfa-abf3-5b98f26bfb82",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# What is the median follower count per age group?\n",
    "from pyspark.sql.functions import expr\n",
    "\n",
    "\n",
    "df_geo_user = clean_user.join(clean_geo, clean_user.ind == clean_geo.ind, \"inner\")\n",
    "df_all = df_geo_user.join(cleaned_pin5, clean_user.ind == cleaned_pin5.ind, \"inner\")\n",
    "\n",
    "df_age_group = df_all.withColumn(\"age_group\", when((col(\"age\") >= 18) & (col(\"age\") <= 24), \"18-24\")\n",
    "                              .when((col(\"age\") >= 25) & (col(\"age\") <= 35), \"25-35\")\n",
    "                              .when((col(\"age\") >= 36) & (col(\"age\") <= 50), \"36-50\")\n",
    "                              .when(col(\"age\") > 50, \"+50\"))\n",
    "\n",
    "df_select = df_age_group.select(\"age_group\", \"follower_count\", \"poster_name\").drop_duplicates()\n",
    "\n",
    "median_ages = df_select.groupBy(\"age_group\").agg(\n",
    "    expr(\"percentile_approx(follower_count, 0.5)\").alias(\"Median_Age\")\n",
    ")\n",
    "median_ages.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c09a1e0c-d24a-49ab-8df3-6960291aa345",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Find how many users joined each year\n",
    "\n",
    "# Filter users who joined between 2015 and 2020\n",
    "users_joined_2015_2020 = clean_user.filter((year(\"date_joined\") >= 2015) & (year(\"date_joined\") <= 2020))\n",
    "\n",
    "# Group by year and count the number of users\n",
    "users_count_by_year = users_joined_2015_2020.groupBy(year(\"date_joined\").alias(\"post_year\")).count().withColumnRenamed(\"count\", \"number_users_joined\")\n",
    "\n",
    "pin_post_year = clean_geo.withColumn(\"post_year\",year(\"timestamp\"))\n",
    "output_df = pin_post_year.join(users_count_by_year, on=\"post_year\", how=\"left\")\n",
    "# output_df = output_df.select(\"post_year\",\"number_users_join\")\n",
    "display(output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e59b16d8-8d26-4ccc-8a1b-05b33481ef0a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Find the median follower count for users who joined between 2015 and 2020\n",
    "\n",
    "pin_task_10 = cleaned_pin5.select(\"ind\", \"follower_count\")\n",
    "user_task_10 = clean_user.select(\"ind\", \"date_joined\")\n",
    "user_task_10 = user_task_10.withColumn(\"post_year\",year(\"date_joined\"))\n",
    "task_10 = user_task_10.join(pin_task_10, on=\"ind\", how=\"inner\").drop_duplicates()\n",
    "\n",
    "median_follow = task_10.groupBy(\"post_year\").agg(\n",
    "    expr(\"percentile_approx(follower_count, 0.5)\").alias(\"median_follower_count\")\n",
    ")\n",
    "median_follow.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4631628b-a530-470f-82f4-bf100a50cf9e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Find the median follower count of users that have joined between 2015 and 2020, based on which age group they are part of.\n",
    "\n",
    "pin_task11 = cleaned_pin5.select('ind', 'follower_count')\n",
    "user_task11 = clean_user.select('ind', 'age', year('date_joined').alias('post_year'))\n",
    "\n",
    "user_task11 = user_task11.withColumn(\"age_group\", when((col(\"age\") >= 18) & (col(\"age\") <= 24), \"18-24\")\n",
    "                              .when((col(\"age\") >= 25) & (col(\"age\") <= 35), \"25-35\")\n",
    "                              .when((col(\"age\") >= 36) & (col(\"age\") <= 50), \"36-50\")\n",
    "                              .when(col(\"age\") > 50, \"+50\"))\n",
    "\n",
    "\n",
    "task11 = pin_task11.join(user_task11, on='ind', how='inner').drop_duplicates()\n",
    "\n",
    "median_follow_age_join = task11.groupBy(\"age_group\", \"post_year\").agg(\n",
    "    expr(\"percentile_approx(follower_count, 0.5)\").alias(\"Median_Followers\")\n",
    ")\n",
    "\n",
    "display(median_follow_age_join)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1861847397600015,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Mount S3 bucket",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
